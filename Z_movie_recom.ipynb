{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJtwwNrifIzR",
        "outputId": "ac6f0676-2a78-4889-c815-b63703a44d61"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow-probability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LOvY7r1FPP--"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade lida==0.0.10 fastapi pydantic pydantic-core"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1v09NSoUxWeW"
      },
      "outputs": [],
      "source": [
        "! pip install pandas\n",
        "! pip install openai==0.28.1\n",
        "! pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wuzCe_6pfRX9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import openai\n",
        "import numpy as np\n",
        "import gradio as gr\n",
        "import pickle\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from openai.embeddings_utils import get_embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mbP45pp0fU0W"
      },
      "outputs": [],
      "source": [
        "openai.api_key = 'Your-openai-key'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "g08-XH7ofajb"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/embedding-movie-recommender/large_movie_data.csv') # we define df to read our csv file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Z6z_VXIqhBEl"
      },
      "outputs": [],
      "source": [
        "# in the df we define a column name \"Embedding\" to store the embedded value of \"Movie\" column. the lambda function goes through each line of Movie column and the\n",
        "# ada module creates the embeddings.\n",
        "# we use the second line 'with open('file_path') to store the pickle file.\n",
        "# the function f:pickel.dump(df,f) is the function that creates embedding vectors. it takes about 12 miniutes to complete.\n",
        "df['Embedding'] = df['Movie'].apply(lambda x: get_embedding(x, engine='text-embedding-ada-002'))\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/embedding-movie-recommender/large_movie_data_embedded.pkl', 'wb') as f:\n",
        "  pickle.dump(df, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "eLndwIF-kPRM"
      },
      "outputs": [],
      "source": [
        "df = pd.read_pickle('/content/drive/MyDrive/Colab Notebooks/embedding-movie-recommender/large_movie_data_embedded.pkl') # we use df.read_pickle('file_path') to read the pickle file. To see it, we need to convert it to CSV.\n",
        "df.to_csv('/content/drive/MyDrive/Colab Notebooks/embedding-movie-recommender/large_movie_data_embedded.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQ6y7zx2mvIQ"
      },
      "outputs": [],
      "source": [
        "# now we need to load our pickle file.\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/embedding-movie-recommender/large_movie_data_embedded.pkl', 'rb') as f:\n",
        "   df = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "W1E4P-WqnYh6"
      },
      "outputs": [],
      "source": [
        "# now that we loaded our embedded data, we create a search function to test our model.\n",
        "# the function 'search_movies' compares df with movie_title (user input from gradio). then n=2 picks second most similar title(first one is the movie title itself we input.)\n",
        "def search_movies(df, movie_title, n=2):\n",
        "  # embedding module creates embedding of movie_title (user input) using the same engine.\n",
        "  embedding = get_embedding(movie_title, engine='text-embedding-ada-002')\n",
        "  # df creates 'similarities' column where it stores similarity value of 'embedding' or (user input movie title) and 'Embedding' or the Movies embedded values.\n",
        "  df['similarities']= df.Embedding.apply(lambda x: cosine_similarity([x], [embedding]))\n",
        "  # store the results in a df called res. res contains the top n values in descending order.\n",
        "  res = df.sort_values('similarities', ascending=False).head(n)\n",
        "  # return the searched Movie title and its corresponding similarity value.\n",
        "  return res.iloc[1]['Movie'], res.iloc[1]['similaritis']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgWdF0m-u_Oe"
      },
      "source": [
        "modifications: in below gradio code, I removed the \"Interpretation='default', to solve the error. in the new version of gradio, this line is causing a bug."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1mosBF5RM5qn"
      },
      "outputs": [],
      "source": [
        "# Define Gradio interface for the recommendation system\n",
        "def gradio_wrapper(movie_title):\n",
        "    top_movie, similarity_score = search_movies(df, movie_title)\n",
        "    return top_movie, similarity_score\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=gradio_wrapper,\n",
        "    inputs=\"text\",\n",
        "    outputs=[\"text\", \"number\"],\n",
        "    #interpretation=\"default\",\n",
        ")\n",
        "iface.launch(share=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
